{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte II - Experimentação\n",
    "## Aluno: Luiz Pedro Gadelha da Silva - 1615080153"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from Perceptron import Perceptron\n",
    "from Perceptron2 import Perceptron2\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nesta segunda parte, cada equipe deverá usar o seu respectivo identificador de exemplos para trabalhar com um arquivo específico. No caso da nossa equipe, o identificador é 3, logo, vamos considerar o arquivo \"data3.txt\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(\"data\", \"data3.txt\")\n",
    "data = np.fromfile(path).reshape(600, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A equipe deve aproveitar o algoritmo construído na Parte I e executar 10 repetições do mesmo para as seguintes configurações: η×I = {0.4, 0.1, 0.01}× {(−100,+ 100),(−0.5,+ 0.5)} em que I é o intervalo a ser utilizado para a distribuição uniforme do valor dos pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_array = [0.4, 0.1, 0.01]\n",
    "weight_interval_array = [(-100, 100), (-0.5, 0.5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assim, há 6 configurações a serem testadas, cada uma delas por 10 repetições."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Combinações ---\n",
      "(0.4, (-100, 100))\n",
      "(0.4, (-0.5, 0.5))\n",
      "(0.1, (-100, 100))\n",
      "(0.1, (-0.5, 0.5))\n",
      "(0.01, (-100, 100))\n",
      "(0.01, (-0.5, 0.5))\n"
     ]
    }
   ],
   "source": [
    "lr_wi_array = list(product(learning_rate_array, weight_interval_array))\n",
    "print(\"--- Combinações ---\")\n",
    "for item in lr_wi_array:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para cada configuração em suas 10 execuções, obter a média e o desvio padrão da quantidade de ajustes efetuados no vetor de pesos e o menor número de épocas até a convergência nestas 10 iterações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Combinação: (0.4, (-100, 100)) ---\n",
      "Vetor de quantidade de ajustes: [122, 8, 172, 287, 196, 159, 169, 335, 242, 375]\n",
      "Vetor de épocas para convergência: [7, 8, 6, 22, 22, 11, 23, 17, 6, 35]\n",
      "\n",
      "--- Combinação: (0.4, (-0.5, 0.5)) ---\n",
      "Vetor de quantidade de ajustes: [5, 3, 10, 10, 10, 3, 2, 8, 9, 9]\n",
      "Vetor de épocas para convergência: [3, 2, 4, 5, 5, 2, 2, 4, 5, 4]\n",
      "\n",
      "--- Combinação: (0.1, (-100, 100)) ---\n",
      "Vetor de quantidade de ajustes: [1907, 2100, 206, 366, 1902, 1263, 624, 1965, 1955, 1791]\n",
      "Vetor de épocas para convergência: [117, 43, 41, 57, 29, 13, 56, 20, 62, 55]\n",
      "\n",
      "--- Combinação: (0.1, (-0.5, 0.5)) ---\n",
      "Vetor de quantidade de ajustes: [16, 9, 14, 13, 9, 11, 15, 12, 3, 13]\n",
      "Vetor de épocas para convergência: [4, 4, 4, 4, 3, 5, 4, 5, 3, 4]\n",
      "\n",
      "--- Combinação: (0.01, (-100, 100)) ---\n",
      "Vetor de quantidade de ajustes: [5211, 6213, 5179, 1797, 10911, 20703, 5513, 18459, 4392, 9919]\n",
      "Vetor de épocas para convergência: [421, 316, 224, 106, 495, 100, 324, 77, 555, 447]\n",
      "\n",
      "--- Combinação: (0.01, (-0.5, 0.5)) ---\n",
      "Vetor de quantidade de ajustes: [55, 42, 110, 17, 93, 103, 107, 16, 80, 112]\n",
      "Vetor de épocas para convergência: [4, 4, 6, 5, 5, 6, 7, 4, 6, 9]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_std_array = []\n",
    "min_epochs_array = []\n",
    "\n",
    "for lr_wi in lr_wi_array:\n",
    "    fits = []\n",
    "    epochs = []\n",
    "    \n",
    "    learning_rate, weight_interval = lr_wi\n",
    "    print(f\"--- Combinação: ({learning_rate}, {weight_interval}) ---\")\n",
    "    \n",
    "    for j in range(10):\n",
    "        neuron = Perceptron2(data, len(data), learning_rate, weight_interval)\n",
    "        neuron.teachPerceptron(verbose = False)\n",
    "        fits.append(neuron.numberOfFitsInTheWeightVector)\n",
    "        epochs.append(neuron.epoch)\n",
    "    \n",
    "    print(f\"Vetor de quantidade de ajustes: {fits}\")\n",
    "    print(f\"Vetor de épocas para convergência: {epochs}\\n\")\n",
    "    \n",
    "    # Obtém média e desvio padrão\n",
    "    mean_std_array.append((np.mean(fits), np.std(fits)))\n",
    "    \n",
    "    # Obtém menor número de épocas até a convergência \n",
    "    min_epochs_array.append(np.min(epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dispor tais resultados sobre a forma de uma tabela e discutir se há uma configuração melhor ou pior que as demais ou se elas são equivalentes. Recomenda-se a utilização do pacote prettytable no notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------------------+-----------------------+------------------------------------------+\n",
      "| Taxa de aprendizado | Intervalo de Pesos | Quantidade de Ajustes | Menor número de épocas para convergência |\n",
      "+---------------------+--------------------+-----------------------+------------------------------------------+\n",
      "|       η = 0.4       |    (-100, 100)     |     206.5 ± 102.05    |                    6                     |\n",
      "|       η = 0.4       |    (-0.5, 0.5)     |       6.9 ± 3.11      |                    2                     |\n",
      "|       η = 0.1       |    (-100, 100)     |    1407.9 ± 699.59    |                    13                    |\n",
      "|       η = 0.1       |    (-0.5, 0.5)     |      11.5 ± 3.58      |                    3                     |\n",
      "|       η = 0.01      |    (-100, 100)     |    8829.7 ± 5938.34   |                    77                    |\n",
      "|       η = 0.01      |    (-0.5, 0.5)     |      73.5 ± 36.14     |                    4                     |\n",
      "+---------------------+--------------------+-----------------------+------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "x = PrettyTable()\n",
    "x.field_names = [\"Taxa de aprendizado\", \"Intervalo de Pesos\", \"Quantidade de Ajustes\", \"Menor número de épocas para convergência\"]\n",
    "for i, item in enumerate(lr_wi_array):\n",
    "    learning_rate, weight_interval = item\n",
    "    mean, std = mean_std_array[i]\n",
    "    min_epoch = min_epochs_array[i]\n",
    "    x.add_row([f\"η = {learning_rate}\", f\"{weight_interval}\", f\"{mean} ± {np.round(std, 2)}\", min_epoch])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando a tabela é possível dizer que: \n",
    "- Quanto ao intervalo de pesos, as combinações que utilizaram o intervalo igual a (-100, 100) obtiveram as piores estatísticas, pois realizaram uma quantidade muito maior de ajustes e necessitaram de um valor maior para o número mínimo de épocas para convergência quando comparadas às combinações que utilizaram o intervalo (-0.5, 0.5).\n",
    "- Quanto a taxa de aprendizado, as combinações que utilizaram a taxa igual a 0.01 obtiveram as piores estatísticas, realizando uma quantidade de ajustes cerca de 5x maior que a obtida pelas demais combinações. Houve uma certa diferença também entre as combinações que utilizaram as taxas 0.1 ou 0.4, tendo estas com a maior taxa de aprendizado realizado menos ajustes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
